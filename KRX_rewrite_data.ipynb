{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "w3W7XQJvl9Hg",
   "metadata": {
    "id": "w3W7XQJvl9Hg"
   },
   "source": [
    "## KRX-Bench 합성 데이터셋 생성 with web text 튜토리얼\n",
    "\n",
    "- **litellm**은 다양한 LLM API를 OpenAI API로 통합하여 사용할 수 있는 라이브러리입니다.\n",
    "- 본 튜토리얼에서는 OpenAI의 `gpt-4o-mini-2024-07-18` 모델을 활용하여 웹에서 수집된 금융 관련 고품질 텍스트 데이터셋 `amphora/rewrite-se-quant`을 정규화한 뒤, QA Instruction 데이터셋으로 변환하는 방법에 대해 다룹니다.\n",
    "- 데이터 생성 파이프라인:\n",
    " 1. 텍스트 데이터를 입력으로 해서 질문 생성\n",
    " 2. 생성된 질문 세트에 대한 답변 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZMgnZQy9owrK",
   "metadata": {
    "id": "ZMgnZQy9owrK"
   },
   "source": [
    "## 1. litellm 설치 및 환경 설정\n",
    "- 필요 라이브러리: pandas, datasets, random, litellm, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Sbz32ONlpzCB",
   "metadata": {
    "id": "Sbz32ONlpzCB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "import random\n",
    "from litellm import completion, batch_completion\n",
    "import os\n",
    "import litellm\n",
    "\n",
    "# OpenAI API key 선언\n",
    "# os.environ[\"OPENAI_API_KEY\"] = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LAUn_JQVpOgQ",
   "metadata": {
    "id": "LAUn_JQVpOgQ"
   },
   "source": [
    "## 2. 데이터셋 로드 및 전처리\n",
    "\n",
    "- `amphora/rewrite-se-quant` 데이터셋은 금융 관련 고품질 웹 텍스트 데이터셋입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e740732-b02d-4045-9954-cb37a755a8cd",
   "metadata": {
    "id": "1e740732-b02d-4045-9954-cb37a755a8cd"
   },
   "outputs": [],
   "source": [
    "# 데이터셋 로드\n",
    "ds = load_dataset('amphora/rewrite-se-quant')['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "KjDvrSfu2-Ix",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KjDvrSfu2-Ix",
    "outputId": "66fb3a9a-49ea-4d49-c3cc-224ee4c9eb37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['link', 'query', 'output'],\n",
       "    num_rows: 21950\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "tC7mEHTMtyXw",
   "metadata": {
    "id": "tC7mEHTMtyXw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I want to know how to price an American call option for non-dividend stock? (with concrete and simple binomial pricing model, with risk neutral assumption)\\nI understand that for an European call option, (in Binomial pricing model), the price is simply:\\n$$V_n(\\\\omega) = \\\\frac{1}{1+r} (PV_{n+1}(\\\\omega H) + QV_{n+1}(\\\\omega T) )\\\\tag1$$\\nand from Early execise of American Call on Non-Dividend paying stock. and many other materials also state that early exercise of American call options is not optimal compared with selling it.\\nHowever, many materials also state or imply that European calls and American calls are identical when the underlying stock pays no dividends, which means (1) should apply right? (for anytime before maturity)\\nThis confuses me as I thought the pricing of an American call option should be:\\n$$V_n(\\\\omega) = max(S(\\\\omega) - K, \\\\frac{1}{1+r} (PV_{n+1}(\\\\omega H) + QV_{n+1}(\\\\omega T))) \\\\tag2$$\\nSo let's say if I have a deep in-the-money American call option for non-dividend stock (not expired), what is the price for this option?\\nBecause since early exercise is not optimal, which add no time value for the American call option, why should one pay for the option according to equation (2) instead of (1)? Especially, when many seems to agree that European calls and American calls are identical when the underlying stock pays no dividends\",\n",
       " 'I\\'m attempting to calculate a GBP yield curve using a USD OIS rate curve and the FX Forward rates using Quantlib. I am trying to replicate the output of a different library, and am close but can\\'t seem to quite get it right.\\nFirstly, bootstrapping the USD yield curve from the OIS swap rates:\\n# Set the calculation date\\nstart_date = ql.Date(1, 2, 2024)\\nql.Settings.instance().evaluationDate = start_date\\n\\n\\n# Define calendar\\ncalendar = ql.UnitedStates(0)\\nconvention = ql.Following\\nendOfMonth = False\\nspot_date = calendar.advance(start_date, 2, ql.Days)\\n\\n# Fixed leg payment frequency and conventions\\nfixed_frequency = ql.Annual\\nfixed_day_count = ql.Actual360()  \\nfixed_convention = convention\\nfixed_payment_convention = convention\\n\\n# Rule for generating the schedule\\nrule = ql.DateGeneration.Backward\\n\\n# Define the overnight index as Fed Funds\\novernight_index = ql.FedFunds()\\n\\n# Market data for OIS rates and their specific maturity dates\\nmaturity_dates = ois_data[\"end_date\"].to_list()  # Specific maturity dates\\nois_rates = ois_data[\"Value\"].to_list()  # Corresponding OIS rates\\n\\n# Create OIS Rate Helpers with specific maturity dates for the Fed Funds rate\\nois_helpers = [\\n    ql.OISRateHelper(\\n        2,\\n        ql.Period(maturity_date - spot_date, ql.Days),\\n        ql.QuoteHandle(ql.SimpleQuote(rate)),\\n        overnight_index,\\n        paymentLag=0,\\n        paymentFrequency=fixed_frequency,\\n        paymentConvention=fixed_payment_convention,\\n        paymentCalendar=calendar,\\n        endOfMonth=endOfMonth,\\n    )\\n    for rate, maturity_date in zip(ois_rates, maturity_dates)\\n]\\n\\n# Bootstrap the OIS curve\\nday_count = ql.Actual365Fixed()\\nois_curve = ql.PiecewiseLogLinearDiscount(start_date, ois_helpers, day_count)\\nusd_yield_curve = ql.YieldTermStructureHandle(ois_curve)\\n\\nWhen I compare the discount factors, I am getting the correct figures.\\nNext, I attempt to bootstrap the GBP yield curve:\\nfx_prices = fx_fwd[\"Value\"].tolist()\\nsettlement_dates = fx_fwd[\"Settlement Date\"].dt.date.tolist()\\njoint_calendar = ql.JointCalendar(\\n    ql.UnitedKingdom(), calendar, ql.JoinHolidays\\n)\\nrate_helpers = [\\n    ql.FxSwapRateHelper(\\n        ql.QuoteHandle(ql.SimpleQuote(price - spot_price)),\\n        ql.QuoteHandle(ql.SimpleQuote(spot_price)),\\n        ql.Period(ql.Date.from_date(settlement_date) - start_date, ql.Days),\\n        0,\\n        joint_calendar,\\n        ql.ModifiedFollowing,\\n        True,\\n        False,\\n        usd_yield_curve,\\n    )\\n    for price, settlement_date in zip(fx_prices, settlement_dates)\\n]\\n\\n# Bootstrap the OIS curve\\nday_count = ql.Actual365Fixed()\\n# day_count = ql.Actual360()\\ngbp_curve = ql.PiecewiseFlatForward(start_date, rate_helpers, day_count)\\ngbp_yield_curve = ql.YieldTermStructureHandle(gbp_curve)\\n\\n\\nThis time when I plot the discount factors, compared with the other library, they are different. Only by between 1-50 bp, but that is enough to throw off instrument pricing further down the line when using these yield curves.\\nI\\'ve tried a few different iterations of the arguments to the helpers but can\\'t seem to get it to work. Any help would be really appreciated.',\n",
       " \"I want to calculate halflife with AR process and/or Ornstein–Uhlenbeck process.\\nmod = AutoReg(lag,exog=exog ,lags=1, trend='ct')\\n \\nres = mod.fit()\\nhalflife = round(-np.log(0.5) / res.params[1],0)\\n\\nres.params[1] gives wrong halflife  value\\nI want to do this with additional regression variable()\\nf,g,h\\nh-g=σ1 #shorter mean reverting process\\ng-f=σ2 #longer mean reverting process\\nso if i add both sides of equation\\nh-f=σ1+σ2\\nhttps://mathtopics.wordpress.com/2013/01/10/half-life-of-the-ar1-process/\\nwithout regressors i can check theta in ouparams or calculate this by ols.\\nmu, sigma, theta = ouparams.find(ds)\",\n",
       " 'Is call/put wing volatility smile calibration approach used in practice? To calibrate an index (SPY) using only more liquid OTM calls/puts, to kind of use an \"if\" condition on K to S0 to determine whether to use call or put formular? More details;\\nliterature I found on the internet usually calibrate vol smiles/skews to call options (Euro SPY), (assuming put-call parity),\\nbut in practice as I know calibration (index) is done to OTM puts and calls, due to more liquidity. Also, looking at IV (BBG terminal option chain data) of puts and calls with same strike, the IV wont be the same, small differences I have observed.\\nI am looking at the calibration code provided here Heston model SPY calibration\\nIt would require a few changes (hopefully) to the code,like changing the option param payoff argument to:\\nif K>S0 payoff \\'call\\' elif K<S0 payoff \\'put\\' else...\\n# Unconstrained problem\\ndef f_Hest(x, rho, sigma, theta, kappa, v0):\\n    Heston_param = Heston_process(mu=r, rho=rho, sigma=sigma, theta=theta, kappa=kappa)\\n    opt_param = Option_param(S0=S0, K=K, T=T, v0=v0, exercise=\"European\", payoff=payoff)\\n    Hest = Heston_pricer(opt_param, Heston_param)\\n    return Hest.FFT(x)\\n\\n\\ninit_vals = [-0.6, 1.0, 0.04, 2.5, 0.04]\\nbounds = ([-1, 1e-15, 1e-15, 1e-15, 1e-15], [1, np.inf, 2, np.inf, 2])\\nparams_Hest = scpo.curve_fit(\\n    f_Hest, strikes, prices, p0=init_vals, bounds=bounds, sigma=spreads, xtol=1e-4, max_nfev=1000\\n)\\n\\nI believe I would get something like this;',\n",
       " 'I am trying understand and replicate this thesis, which is based on, High-frequency trading in a limit order book by (Avellaneda and Stoikov, 2008) and Optimal market making, by Olivier Gueant, 2017, except the thesis uses real historical data to calculate the intensities and uses best bid(ask) as the reference price when calculating the intensities $\\\\lambda^a$($\\\\lambda^b$), whilst Avellaneda uses the mid-price.\\nI currently have a full-day, 10 level limit order book with $0.1$ second increments. I also have the order info such as hidden order, cancellation, MO buy/sell, LO placed etc with the same increments in-sync.\\nTherefore, I can calculate intensities $\\\\lambda_t = \\\\Lambda(\\\\delta_t)$, and solve for $A$ and $k$ in $\\\\Lambda(\\\\delta_t)=Ae^{-k\\\\delta}$, during the time period of the LOB data. As well as the $\\\\sigma$ (assuming constant volatility for now).\\nMain question: How is the back-test actually conducted?\\nFrom what I understand, the bid and ask price are simulated using:\\n$$\\\\begin{align} dS_t^b  & = \\\\sigma S_t^bdW_t^b \\\\\\\\  dS_t^a  & = \\\\sigma S_t^a dW_t^a \\\\end{align}$$\\nand $$\\\\begin{align} \\\\delta_t^b & = S_t - S_t^b \\\\\\\\ \\\\delta_t^a & = S_t^a - S_t,\\\\end{align}$$\\nwhere $S_t$ is the reference price.\\nAnd the MM cash account is modelled by:\\n$$\\nd X_t=\\\\left(S_t+\\\\delta^a\\\\right) d N_t^a-\\\\left(S_t-\\\\delta^b\\\\right) d N_t^b\\n$$\\nwhere $N_t$ is a poisson distribution with the intensity $\\\\lambda_t$, which is calculated from the historical dataset I have.\\nMy confusion lies in their algorithm and simulation. If they simulate the ask and bid price, it obviously won’t follow the fluctuations of the bid-ask spread in the dataset. I.e. if $S_0 = 100$ and $S_3 = 80$ from the simulation, but what if the level 1 bid-ask price is $S_3=101$ and $S_3=103$?\\nFrom algorithm 1 on page 74 of the thesis, it seems that they calculate $\\\\delta^a$ and $\\\\delta^b$ at $t=0$, with starting buy and sell positions in the order book of $LO^a$ and $LO^b$. Then they simulate $S_t^a$ and $S_t^b$ and if the simulated bid-asks meet their orders, then it’s executed.\\nI am not sure how this simulation process is happening. And if we are simulating, $S_t^a$ and $S_t^b$, what happens if $S_t^a<S_t^b$?\\nWhilst in the Avellaneda and Stoikov paper, they only simulate the mid-price and then use the intensities as to whether the MM wealth changes.\\nOr is only $d X_t=(S_t+\\\\delta^a) d N_t^a - …$ simulated using the parameters we calculated from the historical LOB data?\\nSome insights would be greatly appreciated.',\n",
       " \"I'm exploring financial simulations where bootstrapped returns (TxNBoot) are used to derive compounded returns, crucial for longer time horizons (T > 180 months).\\nThis results in a vector of terminal wealth payoffs (NBootx1) at T, typically following a log-normal distribution with minimum values above 0 due to compounding.\\nCan I directly calculate the Sharpe ratio using these payoffs (with mean payoffs and standard deviation of payoffs at maturity)?\\nWhile this seems feasible, I'm encountering challenges when applying other risk-adjusted metrics like the Sortino ratio and Omega ratio, which are traditionally used with returns rather than payoffs. The latter metrics typically rely on thresholds as minimum acceptable returns, such as 0 for the Sortino ratio (or the risk-free rate for the others).\\nAny insights on this and potential alternatives for assessing risk-adjusted performance of these payoffs would be appreciated.  At the end maximizing compound rates and, hence, terminal wealth is what matters to most investors, no?\",\n",
       " 'I am trying to build a Google Sheet formula which calculates the Average True Range of a stock price, pulling in live data from Google Finance. Specifically, I want the 21-day ATR with EMA smoothing.\\nThis is the formula I have today (below), which calculates a 40-day ATR without smoothing.\\nI have tried simply switching 40 to 21, but it generates a function error.\\n=average(ARRAYFORMULA(query(query(transpose(abs(query({query({Googlefinance(\"AAPL\",\"High\",today()-(100),today()),\\nGooglefinance(\"AAPL\",\"low\",today()-(100),today())},\\n\"select Col1,Col2,Col4 order by Col1 desc limit \"&40&\" \"), query(Googlefinance(\"AAPL\",\"close\",today()-(100),today()),\\n\"select Col2 order by Col1 desc limit \"&40&\" offset 1 label Col2 \\'closeyest\\' \")}, \\n\"select Col2-Col3, Col2-Col4, Col3-Col4\"))), \\n\"select max(Col\"&join(\",\\nmax(Col\",row(indirect(\"A1:A\"&40))&\")\")))))\\n\\nHow would I change the formula so it calculates a 21-day ATR with EMA smoothing?\\nHere is the source code of Pine script ATR indicator which works how I need:\\nplot(ta.ema(ta.tr(true), 21), title = \"ATR\", color=color.new(#B71C1C, 0))\\n\\nThank you',\n",
       " \"Imagine we have a certain price movement, where the price starts at 1000 and ends at 1200, with some fluctuations in the middle. For the sake of the example, imagine it's hourly timestamps, and it's a long only strategy. I went ahead and calculated the simple and log returns, as well as the cumulative returns. As expected, the cumulative returns calculated for both the simple and log returns match.\\n\\n\\n\\n\\nprice\\nsimple_returns\\nlog_returns\\ncum_sum_simple\\ncum_sum_log\\n\\n\\n\\n\\n1000\\nnan\\nnan\\nnan\\nnan\\n\\n\\n1100\\n0.10000\\n0.09531\\n1.10000\\n1.10000\\n\\n\\n900\\n-0.18182\\n-0.20067\\n0.90000\\n0.90000\\n\\n\\n800\\n-0.11111\\n-0.11778\\n0.80000\\n0.80000\\n\\n\\n950\\n0.18750\\n0.17185\\n0.95000\\n0.95000\\n\\n\\n1100\\n0.15789\\n0.14660\\n1.10000\\n1.10000\\n\\n\\n1500\\n0.36364\\n0.31015\\n1.50000\\n1.50000\\n\\n\\n1200\\n-0.20000\\n-0.22314\\n1.20000\\n1.20000\\n\\n\\n\\n\\nThis outputs a return of 0.2 (20%), which is expected. (1200 - 1000) / 1000 is also 20%.\\nNow imagine we introduce leverage into the equation, for example 2. From my current understanding, in order to introduce the leverage into the returns, we have to multiply it by the simple returns, not the log returns. We can then calculate the cumulative sum as before. So it would be:\\n\\n\\n\\n\\nprice\\nlev_returns\\ncum_sum_lev\\n\\n\\n\\n\\n1000\\nnan\\nnan\\n\\n\\n1100\\n0.20000\\n1.20000\\n\\n\\n900\\n-0.36364\\n0.76364\\n\\n\\n800\\n-0.22222\\n0.59394\\n\\n\\n950\\n0.37500\\n0.81667\\n\\n\\n1100\\n0.31579\\n1.07456\\n\\n\\n1500\\n0.72727\\n1.85606\\n\\n\\n1200\\n-0.40000\\n1.11364\\n\\n\\n\\n\\nThis means that the final return would be 0.113, or 11.3%. This in itself is already a little counter intuitive—as one would expect the gains to be double, so 40%—but this could in theory make sense since losses (with simple returns) are more amplified than the gains.\\nWhat is really confusing me, is that if we were to calculate the total final return independently of the path the price took to get there—so by taking only the last and first prices—, then:\\nr = ((1200 - 1000) / 1000) * 2 \\nr = 0.4\\nWhat am I missing here?\",\n",
       " \"https://www.wallstreetmojo.com/bootstrapping-yield-curve/\\na) This is the standard method for bootstrapping:\\nFrom the 0.5-year maturity the spot rate or the discount rate is 3% and let us assume the discount rate for 1-year maturity be x%, then\\n100 = 1.75/(1+3%/2)^1 + 101.75/(1+x/2)^2\\nb)why this does not work?\\nwhy we divide the coupon by 2 and don't adjust the power as follows? (assume semi annual coupon so 180 days for the 1st cashflow and 360 for the 2nd cashflow):\\n100 = 1.75/(1+3%)^(180/360) + 101.75/(1+x)^(360/360)\\nc) how would the bootstrapping work assuming you have a coupon paid annually and not S/A?\",\n",
       " 'The formula for minimum variance hedge ratio (MVHR) is conceptually the correlation multiplied by the ratios of volatilities.\\ncorrel (Y,X) * (STDEV Y / STDEV X)\\nSuppose I am a EUR investor purchasing an S&P 500 ETF denominated in USD currency and I want to get the MVHR to determine how much to hedge from USD to EUR.\\nTo apply the above formula, is Y the unhedged S&P 500 returns in EUR or the S&P 500 returns in USD. I.e. should it be the returns in foreign currency or returns in domestic currency (unhedged).\\nAnd is X using the 1M USDEUR FX Forward Rate or the USDEUR spot rate.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['query'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x1VM9ZWHuwRm",
   "metadata": {
    "id": "x1VM9ZWHuwRm"
   },
   "source": [
    "## 3. 합성 데이터셋 생성\n",
    "\n",
    "합성 데이터셋 생성 파이프라인은 다음과 같습니다.\n",
    "1. 온라인 데이터를 사용해서 질문 데이터셋을 생성합니다.\n",
    "2. 생성된 질문 데이터셋에 대한 답변을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "X-R3do6IV4Yj",
   "metadata": {
    "id": "X-R3do6IV4Yj"
   },
   "outputs": [],
   "source": [
    "qrys = []\n",
    "for t in ds['query']:\n",
    "    messages = [\n",
    "    {\"content\": \"Your job is creating quantitative finance questions in fluent Korean. You will be given a English QF question collected from the web. Restructure it to a test-like question, in formal Korean language. Return the question only.\", \"role\": \"system\"},\n",
    "    {\"content\": t, \"role\": \"user\"}]\n",
    "    qrys.append(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9IxQprmRV5aq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9IxQprmRV5aq",
    "outputId": "08be398f-6e28-4fc9-d48f-e73bc80a39ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21950"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qrys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ypGYIINuuvXz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "collapsed": true,
    "id": "ypGYIINuuvXz",
    "outputId": "dba0a481-7ea1-441d-d5a9-c5060a76e17e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/4238 [00:13<7:44:49,  6.58s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(qrys[\u001b[38;5;241m5000\u001b[39m:]), batch_size)):\n\u001b[1;32m     14\u001b[0m     batch_messages \u001b[38;5;241m=\u001b[39m qrys[i:i \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[0;32m---> 16\u001b[0m     batch_responses \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o-mini-2024-07-18\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_messages\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRateLimitError\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(batch_responses):\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/litellm/batch_completion/main.py:100\u001b[0m, in \u001b[0;36mbatch_completion\u001b[0;34m(model, messages, functions, function_call, temperature, top_p, n, stream, stop, max_tokens, presence_penalty, frequency_penalty, logit_bias, user, deployment_id, request_timeout, timeout, max_workers, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(lst), n):\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m lst[i : i \u001b[38;5;241m+\u001b[39m n]\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mmax_workers) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sub_batch \u001b[38;5;129;01min\u001b[39;00m chunks(batch_messages, \u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m message_list \u001b[38;5;129;01min\u001b[39;00m sub_batch:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/concurrent/futures/_base.py:649\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "import openai\n",
    "import litellm\n",
    "from tqdm import tqdm \n",
    "# messages 생성 및 토큰 계산\n",
    "responses = []\n",
    "batch_size = 4  # 한번에 요청할 batch 크기\n",
    "sleep_interval = 1  # 각 배치 사이의 슬립 시간 (초)\n",
    "count = 0\n",
    "# litellm의 verbose 설정\n",
    "litellm.set_verbose = False  # 초기 설정은 False로\n",
    "\n",
    "for i in tqdm(range(0, len(qrys[5000:]), batch_size)):\n",
    "    batch_messages = qrys[i:i + batch_size]\n",
    "\n",
    "    batch_responses = batch_completion(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=batch_messages\n",
    "    )\n",
    "    if 'RateLimitError' in str(batch_responses):\n",
    "        break\n",
    "    else :\n",
    "        responses.extend(batch_responses)\n",
    "        count += 1\n",
    "\n",
    "    # \"Give Feedback / Get Help\" 메시지 확인\n",
    "\n",
    "\n",
    "    time.sleep(sleep_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7Ho8eg5QfNoc",
   "metadata": {
    "id": "7Ho8eg5QfNoc"
   },
   "outputs": [],
   "source": [
    "question_resps = [i.choices[0].message.content for i in responses]\n",
    "total_prompt_tokens_for_q = sum([r.usage.prompt_tokens for r in responses])\n",
    "total_completion_tokens_for_q = sum([r.usage.completion_tokens for r in responses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "C5T7n4IMexgA",
   "metadata": {
    "id": "C5T7n4IMexgA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:20<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(qrys), batch_size)):\n\u001b[1;32m     27\u001b[0m     batch_messages \u001b[38;5;241m=\u001b[39m qrys[i:i \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[0;32m---> 29\u001b[0m     batch_responses \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o-mini-2024-07-18\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_messages\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRateLimitError\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(batch_responses):\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/litellm/batch_completion/main.py:100\u001b[0m, in \u001b[0;36mbatch_completion\u001b[0;34m(model, messages, functions, function_call, temperature, top_p, n, stream, stop, max_tokens, presence_penalty, frequency_penalty, logit_bias, user, deployment_id, request_timeout, timeout, max_workers, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(lst), n):\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m lst[i : i \u001b[38;5;241m+\u001b[39m n]\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mmax_workers) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sub_batch \u001b[38;5;129;01min\u001b[39;00m chunks(batch_messages, \u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m message_list \u001b[38;5;129;01min\u001b[39;00m sub_batch:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/concurrent/futures/_base.py:649\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 답변 생성용 prompt 포맷팅\n",
    "qrys = []\n",
    "for t in question_resps:\n",
    "    messages = [\n",
    "    {\"content\":\"You are a skilled financial expert in Korea. Make a response for the question. DO NOT introduce yourself.\",\"role\":\"system\"},\n",
    "    { \"content\": t,\"role\": \"user\"}]\n",
    "    qrys.append(messages)\n",
    "\n",
    "# 2. 생성된 질문에 대한 답변 생성\n",
    "\n",
    "\n",
    "\n",
    "# messages 생성 및 토큰 계산\n",
    "responses = []\n",
    "batch_size = 4  # 한번에 요청할 batch 크기\n",
    "sleep_interval = 1  # 각 배치 사이의 슬립 시간 (초)\n",
    "\n",
    "# litellm의 verbose 설정\n",
    "litellm.set_verbose = False  # 초기 설정은 False로\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, len(qrys), batch_size)):\n",
    "    batch_messages = qrys[i:i + batch_size]\n",
    "\n",
    "    batch_responses = batch_completion(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=batch_messages\n",
    "    )\n",
    "    if 'RateLimitError' in str(batch_responses):\n",
    "        break\n",
    "    else :\n",
    "        responses.extend(batch_responses)\n",
    "        count += 1\n",
    "\n",
    "    # \"Give Feedback / Get Help\" 메시지 확인\n",
    "\n",
    "\n",
    "    time.sleep(sleep_interval)\n",
    "\n",
    "response_resps = [i.choices[0].message.content for i in responses]\n",
    "total_prompt_tokens_for_a = sum([r.usage.prompt_tokens for r in responses])\n",
    "total_completion_tokens_for_a = sum([r.usage.completion_tokens for r in responses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98740e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'content': 'You are a skilled financial expert in Korea. Make a response for the question. DO NOT introduce yourself.',\n",
       "   'role': 'system'},\n",
       "  {'content': '비배당 주식에 대한 미국식 콜 옵션의 가격 책정 방법에 대해 설명하시오. 구체적이고 간단한 이항 모형을 사용하고 위험 중립 가정을 고려하여 다음 질문에 답하십시오. \\n\\n유럽식 콜 옵션의 경우, 이항 가격 모형에서 가격은 다음과 같이 표현됩니다:\\n$$V_n(\\\\omega) = \\\\frac{1}{1+r} (PV_{n+1}(\\\\omega H) + QV_{n+1}(\\\\omega T) )\\\\tag1$$\\n\\n그러나 미국식 콜 옵션의 조기 행사에 대해 다양한 자료에서 조기 행사가 최적이지 않다고 언급하고 있습니다. 또한, 비배당 주식의 경우 유럽식 콜 옵션과 미국식 콜 옵션이 동일하다는 설명도 존재합니다. \\n\\n이러한 내용을 바탕으로, 비배당 주식에 대해 깊게 인더머니 상태에 있는 미국식 콜 옵션이 만료되지 않은 경우, 이 옵션의 가격을 찾아보세요. 조기 행사가 최적이 아니기 때문에 미국식 콜 옵션의 가격은 시간 가치를 추가하지 않으며, 따라서 (2) 식을 사용하는 이유는 무엇인지 설명하시오. \\n귀하의 결론을 도출하는 데 있어 (1) 식과 (2) 식의 차이를 비교하십시오.',\n",
       "   'role': 'user'}],\n",
       " [{'content': 'You are a skilled financial expert in Korea. Make a response for the question. DO NOT introduce yourself.',\n",
       "   'role': 'system'},\n",
       "  {'content': 'GBP 수익률 곡선을 USD OIS 금리 곡선 및 FX 포워드 rates를 사용하여 Quantlib로 계산하려고 합니다. 다른 라이브러리의 출력을 재현하려고 하였으나, 정확하게 일치하지 않는 문제를 겪고 있습니다. 다음의 과정을 통해 EUR 수익률 곡선을 부트스트래핑하고 있는 상황에서 발생한 문제를 해결하기 위한 방법을 설명하십시오.\\n\\n1. USD OIS 스왑 금리를 통해 USD 수익률 곡선을 부트스트래핑 하는 방법을 설명하십시오.\\n2. 부트스트래핑 후 도출된 할인 요인들을 비교한 결과, 정확한 값을 얻었다고 하였습니다. 이 과정을 통해 어떤 데이터를 사용하였으며, 이를 어떻게 활용했는지 기술하십시오.\\n3. GBP 수익률 곡선을 부트스트래핑하는 과정에서 발생한 문제를 설명하고, 해당 문제를 해결하기 위한 두 가지 가능한 접근 방식을 제시하십시오.\\n4. 최종적으로 GBP 도출 시, 할인 요인들이 다른 라이브러리와 다르게 나타나는 이유는 무엇인지에 대해 설명하십시오.',\n",
       "   'role': 'user'}],\n",
       " [{'content': 'You are a skilled financial expert in Korea. Make a response for the question. DO NOT introduce yourself.',\n",
       "   'role': 'system'},\n",
       "  {'content': \"AR 과정 및/또는 Ornstein-Uhlenbeck 과정에서 반감기를 계산하고자 합니다. 다음의 모델을 사용하여 반감기를 구하려고 합니다:\\n\\n```python\\nmod = AutoReg(lag, exog=exog, lags=1, trend='ct')\\nres = mod.fit()\\nhalflife = round(-np.log(0.5) / res.params[1], 0)\\n```\\n\\n그러나 `res.params[1]`을 사용하여 계산한 반감기 값이 올바르지 않습니다. 추가 회귀 변수를 사용하여 반감기를 계산하고 싶습니다. \\n\\n다음의 방정식이 주어졌을 때:\\n- \\\\( h - g = \\\\sigma_1 \\\\) (짧은 평균회귀 과정)\\n- \\\\( g - f = \\\\sigma_2 \\\\) (긴 평균회귀 과정)\\n\\n양변을 더하면 다음과 같은 식이 됩니다:\\n- \\\\( h - f = \\\\sigma_1 + \\\\sigma_2 \\\\)\\n\\n회귀자가 없는 경우에는 `ouparams`에서 θ를 확인하거나 OLS를 통해 이를 계산할 수 있습니다. 다음의 식을 사용하여 μ, σ, θ를 계산합니다:\\n- \\\\( \\\\mu, \\\\sigma, \\\\theta = ouparams.find(ds) \\\\)\\n\\n위의 내용을 기반으로, 반감기를 보다 정확하게 계산하기 위한 방법을 설명하시오.\",\n",
       "   'role': 'user'}],\n",
       " [{'content': 'You are a skilled financial expert in Korea. Make a response for the question. DO NOT introduce yourself.',\n",
       "   'role': 'system'},\n",
       "  {'content': '콜/풋 윙 변동성 스마일 보정 방법은 실제로 사용되고 있습니까? 더 유동적인 OTM 콜/풋만을 이용하여 지수(SPY)를 보정하는 경우, K와 S0에 대한 \"if\" 조건을 적용하여 콜 또는 풋 공식을 결정하는 방법은 어떤가요? 일반적으로 인터넷에서 찾은 문헌에서는 변동성 스마일/스큐를 콜 옵션(유럽식 SPY)에 보정하지만, 실제로는 더 많은 유동성으로 인해 OTM 풋과 콜에 대한 보정이 이루어진다는 것을 알고 있습니다. 또한 동일한 행사가를 갖는 풋과 콜의 IV를 살펴보면, IV가 동일하지 않으며 작은 차이가 관찰되었습니다. 제가 참고하고 있는 보정 코드에서는 Heston 모델 SPY 보정을 다루고 있으며, 옵션 매개변수의 성과 인수를 변경할 필요가 있음을 느낍니다. 즉, K가 S0보다 클 경우 \\'콜\\' 매출, K가 S0보다 작을 경우 \\'풋\\' 매출, 그 외의 경우는...와 같은 식입니다. 이러한 개념을 바탕으로 Heston 모델을 활용한 옵션 보정에 대한 질문을 서술해 주세요.',\n",
       "   'role': 'user'}]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frE_0znEvyJn",
   "metadata": {
    "id": "frE_0znEvyJn"
   },
   "source": [
    "## 5. 데이터셋 저장 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "QHdtq_CBj9d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QHdtq_CBj9d5",
    "outputId": "920dd462-2d25-4224-df0e-842ae424badb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 4000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(question_resps),len(response_resps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777041ea-8ed6-404e-a01b-91beeeb33ea9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "777041ea-8ed6-404e-a01b-91beeeb33ea9",
    "outputId": "b4871d80-ead5-422d-ed23-126002801cd8"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'': ds[1000:5000]['query'], 'question': question_resps, 'response': response_resps})\n",
    "\n",
    "# CSV 파일 저장\n",
    "df.to_csv(\"rewrite-se-quant_final.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# HuggingFace Hub 업로드 - token에 개인 HuggingFace 토큰을 입력해주시면 됩니다.\n",
    "# result_df = Dataset.from_pandas(df)\n",
    "\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mTyR2-CNv02h",
   "metadata": {
    "id": "mTyR2-CNv02h"
   },
   "source": [
    "## 참고자료\n",
    "\n",
    "- [alvanlii/finance-textbooks](https://huggingface.co/datasets/alvanlii/finance-textbooks)\n",
    "- [litellm Docs](https://docs.litellm.ai/)\n",
    "- [Cosmopedia GitHub](https://github.com/huggingface/cosmopedia)\n",
    "- [Cosmopedia Blog](https://huggingface.co/blog/cosmopedia)\n",
    "- [Textbooks Are All You Need](https://arxiv.org/pdf/2306.11644)\n",
    "- [Learning to Generate Instruction Tuning Datasets for Zero-Shot Task Adaptation](https://arxiv.org/abs/2402.18334)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "fromson_test",
   "language": "python",
   "name": "fromson"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
